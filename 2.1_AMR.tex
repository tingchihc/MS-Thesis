Abstract Meaning Representation (AMR)~\cite{garg2018stochastic, ballesteros2017amr, lyu2018amr} functions as a robust semantic representation language, employing rooted, labeled, directed, and acyclic graphs to encapsulate entire sentences. This representation brings forth two pivotal advantages. Firstly, AMR serves as a conduit for semantic representation, adept at capturing the intricate structural nuances within sentences, thereby delineating the relationships that underpin various entities. Secondly, AMR seamlessly integrates semantic role labeling, shedding light on the nuanced roles assumed by different words in a sentence, such as agents, patients, or locations.

The strength of AMR lies in its holistic approach to language representation. AMR not only enhances semantic clarity but also facilitates a more profound understanding of the relationships inherent in linguistic expressions. This depth is particularly valuable when unraveling complex narratives or dissecting intricate layers of meaning within the text. Comparatively, when juxtaposed with Information Extraction (IE)~\cite{zheng2023survey, 10221008}, AMR emerges as a comprehensive information tool. Unlike IE, which is confined to extracting predefined information from textual sources and struggles with untrained sentences, AMR exhibits the versatility to analyze diverse sentences through its nuanced semantic representation.

Harnessing the advantages of AMR, this thesis employs IBM AMR parser~\footnote{\url{https://github.com/IBM/transition-amr-parser}} for extracting textual sources. By doing so, it not only dissects the relationships between events and entities but also benefits from the inherent depth that AMR brings to the semantic analysis of linguistic expressions. 
