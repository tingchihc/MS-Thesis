In order to train our system, we need a dataset of claims whose facts are drawn from multiple documents along with the entailment label of each claim. We build our dataset on top of the Multi-News summarization dataset \cite{alex2019multinews}, which contains sets of multiple text documents along with human-written summaries of each set. Because the Multi-News dataset doesn't have claims specifically made for fact-checking and lacks images for the news articles, we use Llama-2-70b~\cite{touvron2023llama}. We ask it to create labeled claims from each set of documents and get news images from Google. In each group of Multi-News documents, we use the human-written multi-document summary to generate 30 claims (ten of each type), giving us a dataset of 1,291,168 labeled claims. Additionally, we collect 111,905 images for our multimodal multi-document dataset. The prompts include sections with a task description, example, and instructions, which are fully detailed in appendices~\ref{ase:app_prompt_llama2}.


%Because the Multi-News dataset lacks claims specifically tailored for fact-checking tasks and the images for the news articles, we prompt Llama-2-70b~\cite{touvron2023llama} to generate labeled claims from each set of documents and scrape the news images from Google. Within each group of Multi-News documents, we leverage the human-written multi-document summary to generate 30 claims (ten of each entailment type), resulting in a dataset of 1,291,168 labeled claims. In addition, we scrape the 111,905 images for our multimodal multi-document dataset. The specific prompts contain sections containing a task description, example, and instructions. We show the complete prompts in the appendices~\ref{ase:app_prompt_llama2}.
