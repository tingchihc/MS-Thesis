Social media constantly provides us with a mix of images, videos, and text from various sources. Human fact-checkers, in their efforts to verify the accuracy of this information, often spend 2-3 hours on a single post, carefully examining all the content. Human fact-checkers not only verify the information's relevance to its sources but also need to assess its accuracy in terms of entailment, neutrality, and contradiction. These three categories ensure that the statement is appropriately related to the sources. To assist human fact-checkers, we propose an evidence summarization model, \textbf{MetaSumPerceiver},  designed to create concise summaries tailored to specific claims. \textbf{MetaSumPerceiver}, accepting inputs in the form of documents, images, and a claim, aims to facilitate fact-checking tasks.
 
To evaluate the effectiveness of the \textbf{MetaSumPerceiver} model, we also introduce the \textbf{KG2Claim} approach. This approach employs knowledge graphs and multimodal coreference resolution, efficiently integrating information from multimodal multi-document sources. The results indicate that more than 70\% of our generated claims are entailment claims, signifying that the majority of claims are related to multimodal multi-document sources. Subsequent experiments of \textbf{MetaSumPerceiver} were conducted on both an existing benchmark and a new dataset of multi-document claims, which we contributed. The results indicate a notable improvement over the state-of-the-art approach, achieving a 4.2\% better performance in the claim verification task on the MOCHEG dataset. Moreover, our approach demonstrated robust performance on the Multi-News-Fact-Checking dataset. This thesis contributes an evidence summarization model aimed at aiding human fact-checkers in assessing the truthfulness of claims through concise summaries tailored to specific claims. Furthermore, we introduce a practical multimodal multi-document claim generation approach that consolidates knowledge from different documents.